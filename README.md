# llm-cognitive-fields

**Visualizing Multichannel Cognitive Dynamics in Large Language Models**

This repository supports the research project:  
**"Mapping Cognitive Fields: Visualizing Multichannel Dynamics in Large Language Model Responses"**

---

## üß† Overview

We propose a new framework for interpreting large language model (LLM) responses using dynamic multichannel field visualizations. Each LLM output is analyzed along six emergent cognitive dimensions:

- **Red** ‚Äì Semantic Precision  
- **Green** ‚Äì Emotional Tone Modulation  
- **Blue** ‚Äì Structural Recursion Depth  
- **Yellow** ‚Äì Temporal Coherence  
- **Cyan** ‚Äì Novelty Divergence  
- **Magenta** ‚Äì Ethical Calibration  

These dimensions are visualized as radar charts, field resonance overlays, and statistical variance plots. The method is designed to reveal latent tensions and stability patterns during LLM generation, with applications in interpretability, safety, and user interaction design.

---

## üìÅ Repository Contents

```
/images/              # Raw cognitive field visualizations
  /statistical/       # P301 series ("Tell me a joke") with 33+ samples and interleaved P406 wildcard probes
  /conceptual/        # 173+ cross-prompt samples activating single or composite channels
  /composite/         # Multi-channel resonance and metaphor stacking examples

/notebooks/           # Optional Jupyter notebooks for interactive analysis
/appendix/            # Prompt mappings and figure index (e.g., Appendix B, C)
/results/             # Channel-wise statistics, radar overlays, and empirical figures per prompt

analysis_pipeline.py  # Master Python analysis script (Appendix A)
README.md             # This file
```

---

P406 wildcard prompts (e.g., "Explain freedom to a machine using only metaphors.") are used as entropy probes inserted at regular intervals within the P301 statistical run to test attractor basin stability and prompt inertia.

